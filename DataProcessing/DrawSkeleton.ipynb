{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-11T10:08:57.047907Z",
     "start_time": "2025-11-11T10:08:48.757012Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import mediapipe as mp\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "if sys.platform == 'win32':\n",
    "    os.environ[\"PATH\"] += os.pathsep + r\"C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WinGet\\Packages\\Gyan.FFmpeg.Shared_Microsoft.Winget.Source_8wekyb3d8bbwe\\ffmpeg-6.1.1-full_build-shared\\bin\"\n",
    "    from torchaudio._extension.utils import _init_dll_path\n",
    "    _init_dll_path()  # Đảm bảo load DLL từ PATH\n",
    "import torchcodec\n",
    "print(torchcodec.__version__)\n",
    "\n",
    "# --- 1. Khởi tạo các công cụ MediaPipe ---\n",
    "print(\"Khởi tạo MediaPipe Holistic...\")\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# *** ĐỊNH NGHĨA Kiểu VẼ MÀU XANH LÁ ***\n",
    "# Đây là mấu chốt: chúng ta sẽ vẽ keypoint MỚI bằng màu xanh\n",
    "# BGR color: (0, 255, 0) là màu xanh lá\n",
    "drawing_spec_green = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)\n",
    "drawing_spec_green_connect = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "\n",
    "\n",
    "# --- 2. Tải video mẫu từ dataset ---\n",
    "print(\"Đang tải dataset (sử dụng cache nếu có)...\")\n",
    "ds = load_dataset(\"asthalochan/American_Sign_Language\")\n",
    "video_item = ds['train'][1] # Lấy video đầu tiên để test\n",
    "video_tensor = video_item['video'][:]\n",
    "\n",
    "print(\"Đã lấy video mẫu.\")\n",
    "\n",
    "# --- 3. Chuẩn bị video (Tensor -> NumPy) ---\n",
    "# Chuyển (T, C, H, W) sang (T, H, W, C)\n",
    "video_np = video_tensor.numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "# Đảm bảo video là uint8 (0-255)\n",
    "if video_np.dtype != np.uint8:\n",
    "    print(\"Chuyển đổi video sang uint8...\")\n",
    "    video_np_uint8 = (video_np * 255).astype(np.uint8)\n",
    "else:\n",
    "    video_np_uint8 = video_np\n",
    "\n",
    "print(f\"Video sẵn sàng để xử lý, shape: {video_np_uint8.shape}\")\n",
    "\n",
    "# --- 4. Xử lý video và VẼ ĐÈ keypoint MỚI (màu xanh) ---\n",
    "output_frames = [] # Nơi lưu các frame đã được vẽ\n",
    "\n",
    "print(\"Bắt đầu xử lý video và vẽ keypoint MỚI (màu xanh lá)...\")\n",
    "with mp_holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "    # Dùng tqdm để xem tiến trình\n",
    "    for frame in tqdm(video_np_uint8, desc=\"Đang xử lý frames\"):\n",
    "\n",
    "        # MediaPipe cần frame ở dạng C-contiguous và read-only\n",
    "        # (frame.copy() giải quyết cả hai)\n",
    "        # Đồng thời, chúng ta cần một bản sao để vẽ lên\n",
    "        annotated_frame = frame.copy()\n",
    "\n",
    "        # Xử lý frame (MediaPipe nhận RGB, video của bạn đã là RGB)\n",
    "        results = holistic.process(frame)\n",
    "\n",
    "        # BẮT ĐẦU VẼ ĐÈ (MÀU XANH)\n",
    "\n",
    "        # 1. Vẽ Pose (thân)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=annotated_frame,\n",
    "            landmark_list=results.pose_landmarks,\n",
    "            connections=mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=drawing_spec_green,\n",
    "            connection_drawing_spec=drawing_spec_green_connect)\n",
    "\n",
    "        # 2. Vẽ Face (mặt)\n",
    "        # Chúng ta bỏ qua phần lưới (tesselation) cho đỡ rối\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=annotated_frame,\n",
    "            landmark_list=results.face_landmarks,\n",
    "            connections=mp_holistic.FACEMESH_CONTOURS, # Chỉ vẽ viền\n",
    "            landmark_drawing_spec=drawing_spec_green,\n",
    "            connection_drawing_spec=drawing_spec_green_connect)\n",
    "\n",
    "        # 3. Vẽ Tay Trái\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=annotated_frame,\n",
    "            landmark_list=results.left_hand_landmarks,\n",
    "            connections=mp_holistic.HAND_CONNECTIONS,\n",
    "            landmark_drawing_spec=drawing_spec_green,\n",
    "            connection_drawing_spec=drawing_spec_green_connect)\n",
    "\n",
    "        # 4. Vẽ Tay Phải\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=annotated_frame,\n",
    "            landmark_list=results.right_hand_landmarks,\n",
    "            connections=mp_holistic.HAND_CONNECTIONS,\n",
    "            landmark_drawing_spec=drawing_spec_green,\n",
    "            connection_drawing_spec=drawing_spec_green_connect)\n",
    "\n",
    "        # Thêm frame đã được vẽ vào danh sách\n",
    "        output_frames.append(annotated_frame)\n",
    "\n",
    "print(\"Xử lý hoàn tất!\")\n",
    "\n",
    "# --- 5. Lưu video kết quả ---\n",
    "output_filename = \"TEST_mediapipe_vs_data.mp4\"\n",
    "print(f\"Đang lưu video kết quả vào file: {output_filename}...\")\n",
    "\n",
    "iio.imwrite(\n",
    "    output_filename,\n",
    "    output_frames,\n",
    "    fps=25, # Giả định 25 FPS\n",
    "    codec='libx264'\n",
    ")\n",
    "\n",
    "print(f\"Đã lưu thành công! Hãy mở file '{output_filename}' để kiểm tra.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n",
      "Khởi tạo MediaPipe Holistic...\n",
      "Đang tải dataset (sử dụng cache nếu có)...\n",
      "Đã lấy video mẫu.\n",
      "Video sẵn sàng để xử lý, shape: (76, 480, 640, 3)\n",
      "Bắt đầu xử lý video và vẽ keypoint MỚI (màu xanh lá)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang xử lý frames: 100%|██████████| 76/76 [00:03<00:00, 24.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xử lý hoàn tất!\n",
      "Đang lưu video kết quả vào file: TEST_mediapipe_vs_data.mp4...\n",
      "Đã lưu thành công! Hãy mở file 'TEST_mediapipe_vs_data.mp4' để kiểm tra.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T10:22:33.637078Z",
     "start_time": "2025-11-11T10:22:09.384837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Khởi tạo các công cụ MediaPipe ---\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Định nghĩa kiểu vẽ (màu xanh lá)\n",
    "drawing_spec_green = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)\n",
    "drawing_spec_green_connect = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "\n",
    "# --- 2. Định nghĩa đường dẫn file ---\n",
    "video_path = \"C:\\\\Users\\\\Admin\\\\Documents\\\\HUST\\\\2025.1\\\\Project3\\\\Code\\\\Video_Internet\\\\hello.mp4\"\n",
    "output_video_path = \"hello_skeleton.mp4\"\n",
    "\n",
    "print(f\"Bắt đầu trực quan hóa cho video: {video_path}\")\n",
    "\n",
    "# --- 3. Đọc video đầu vào ---\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Lỗi: Không thể mở file video: {video_path}\")\n",
    "else:\n",
    "    # Lấy thông số video (chiều rộng, cao, fps) để ghi file mới\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # --- 4. Tạo đối tượng Ghi Video (VideoWriter) ---\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Bộ mã hóa cho .mp4\n",
    "    writer = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    print(f\"Đang xử lý và lưu kết quả vào: {output_video_path}\")\n",
    "\n",
    "    # --- 5. Vòng lặp xử lý từng frame ---\n",
    "    with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read() # Đọc 1 frame (dạng BGR)\n",
    "            if not ret:\n",
    "                break # Hết video\n",
    "\n",
    "            # 1. Chuyển BGR -> RGB cho MediaPipe\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # 2. Xử lý\n",
    "            results = holistic.process(frame_rgb)\n",
    "\n",
    "            # 3. Vẽ skeleton\n",
    "            # Chúng ta vẽ trên frame BGR gốc (frame)\n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            # Vẽ Pose\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=annotated_frame,\n",
    "                landmark_list=results.pose_landmarks,\n",
    "                connections=mp_holistic.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=drawing_spec_green,\n",
    "                connection_drawing_spec=drawing_spec_green_connect)\n",
    "\n",
    "            # Vẽ Face (chỉ viền)\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=annotated_frame,\n",
    "                landmark_list=results.face_landmarks,\n",
    "                connections=mp_holistic.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=drawing_spec_green,\n",
    "                connection_drawing_spec=drawing_spec_green_connect)\n",
    "\n",
    "            # Vẽ Tay Trái\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=annotated_frame,\n",
    "                landmark_list=results.left_hand_landmarks,\n",
    "                connections=mp_holistic.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=drawing_spec_green,\n",
    "                connection_drawing_spec=drawing_spec_green_connect)\n",
    "\n",
    "            # Vẽ Tay Phải\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=annotated_frame,\n",
    "                landmark_list=results.right_hand_landmarks,\n",
    "                connections=mp_holistic.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=drawing_spec_green,\n",
    "                connection_drawing_spec=drawing_spec_green_connect)\n",
    "\n",
    "            # 4. Ghi frame đã vẽ vào file video mới\n",
    "            writer.write(annotated_frame)\n",
    "\n",
    "    # Giải phóng tài nguyên\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"\\nHoàn tất trực quan hóa!\")"
   ],
   "id": "c5a514d4b8148a50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu trực quan hóa cho video: C:\\Users\\Admin\\Documents\\HUST\\2025.1\\Project3\\Code\\Video_Internet\\hello.mp4\n",
      "Đang xử lý và lưu kết quả vào: hello_skeleton.mp4\n",
      "\n",
      "Hoàn tất trực quan hóa!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T10:33:06.281834Z",
     "start_time": "2025-11-11T10:30:31.084971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# --- 1. HÀM TRÍCH XUẤT KEYPOINT (Giống như trước, đã tối ưu) ---\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "NUM_POSE_LANDMARKS = 33\n",
    "NUM_FACE_LANDMARKS = 468\n",
    "NUM_HAND_LANDMARKS = 21\n",
    "TOTAL_FEATURES = (NUM_POSE_LANDMARKS * 4) + (NUM_FACE_LANDMARKS * 3) + (NUM_HAND_LANDMARKS * 3 * 2) # = 1662\n",
    "\n",
    "# Mảng zero cố định để dùng khi không phát hiện\n",
    "ZERO_POSE = np.zeros(NUM_POSE_LANDMARKS * 4)\n",
    "ZERO_FACE = np.zeros(NUM_FACE_LANDMARKS * 3)\n",
    "ZERO_HAND = np.zeros(NUM_HAND_LANDMARKS * 3)\n",
    "ZERO_FRAME_KEYPOINTS = np.concatenate([ZERO_POSE, ZERO_FACE, ZERO_HAND, ZERO_HAND])\n",
    "\n",
    "def extract_holistic_keypoints(video_frames_rgb_list):\n",
    "    \"\"\"\n",
    "    Hàm này nhận vào một list các frame RGB (H, W, C)\n",
    "    và trả về một mảng keypoints (T, 1662).\n",
    "    \"\"\"\n",
    "    all_frame_keypoints = []\n",
    "\n",
    "    with mp_holistic.Holistic(\n",
    "        static_image_mode=False,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        for frame in video_frames_rgb_list:\n",
    "            # Xử lý frame và lấy kết quả\n",
    "            results = holistic.process(frame)\n",
    "\n",
    "            # Trích xuất với kiểm tra 'None'\n",
    "            pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else ZERO_POSE\n",
    "            face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else ZERO_FACE\n",
    "            lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else ZERO_HAND\n",
    "            rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else ZERO_HAND\n",
    "\n",
    "            # Gộp tất cả (1662 features)\n",
    "            frame_keypoints = np.concatenate([pose, face, lh, rh])\n",
    "            all_frame_keypoints.append(frame_keypoints)\n",
    "\n",
    "    return np.array(all_frame_keypoints)\n",
    "\n",
    "# --- 2. HÀM CHUẨN BỊ VIDEO TỪ TENSOR ---\n",
    "def prepare_video_frames(video_tensor):\n",
    "    \"\"\"\n",
    "    Chuyển video tensor từ (T, C, H, W) sang list các frame (H, W, C)\n",
    "    và đảm bảo là uint8.\n",
    "    \"\"\"\n",
    "    # (T, C, H, W) -> (T, H, W, C)\n",
    "    video_np = video_tensor.numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "    # Đảm bảo là uint8 (0-255)\n",
    "    if video_np.dtype != np.uint8:\n",
    "        if np.max(video_np) <= 1.01: # Check nếu là float 0-1\n",
    "            video_np_uint8 = (video_np * 255).astype(np.uint8)\n",
    "        else:\n",
    "            video_np_uint8 = video_np.astype(np.uint8) # Chuyển đổi trực tiếp\n",
    "    else:\n",
    "        video_np_uint8 = video_np\n",
    "\n",
    "    # MediaPipe xử lý tốt nhất với list các frame\n",
    "    return [frame for frame in video_np_uint8]\n",
    "\n",
    "# --- 3. SCRIPT CHÍNH ĐỂ XỬ LÝ DATASET ---\n",
    "def process_huggingface_dataset(ds, output_dir):\n",
    "    \"\"\"\n",
    "    Lặp qua dataset, trích xuất keypoints, và lưu theo định dạng {label}_{index}.npy\n",
    "    \"\"\"\n",
    "\n",
    "    # Tạo thư mục đầu ra\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Lấy dataset 'train'\n",
    "    train_ds = ds['train']\n",
    "\n",
    "    # Lấy danh sách tên nhãn (ví dụ: 'A', 'B', 'milk', 'hello'...)\n",
    "    label_names = train_ds.features['label'].names\n",
    "    print(f\"Đã tìm thấy {len(label_names)} nhãn.\")\n",
    "\n",
    "    print(f\"Bắt đầu xử lý {len(train_ds)} video...\")\n",
    "\n",
    "    # Lặp qua toàn bộ dataset\n",
    "    for i in tqdm(range(len(train_ds)), desc=\"Đang xử lý dataset\"):\n",
    "        try:\n",
    "            # 1. Lấy thông tin\n",
    "            item = train_ds[i]\n",
    "            label_id = item['label']\n",
    "            label_name = label_names[label_id]\n",
    "            video_index = i # Sử dụng index 'i'\n",
    "\n",
    "            # 2. Tạo tên file và đường dẫn\n",
    "            output_filename = f\"{label_name}_{video_index}.npy\"\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "            # 3. Bỏ qua nếu đã xử lý\n",
    "            if os.path.exists(output_path):\n",
    "                continue\n",
    "\n",
    "            # 4. Lấy video tensor\n",
    "            video_tensor = item['video'][:]\n",
    "\n",
    "            # 5. Chuẩn bị frames (Tensor -> List[np.array])\n",
    "            frames_list = prepare_video_frames(video_tensor)\n",
    "            if not frames_list:\n",
    "                warnings.warn(f\"Video {i} (nhãn {label_name}) bị rỗng.\")\n",
    "                continue\n",
    "\n",
    "            # 6. Trích xuất keypoints\n",
    "            keypoints_data = extract_holistic_keypoints(frames_list)\n",
    "\n",
    "            # 7. Lưu file .npy\n",
    "            np.save(output_path, keypoints_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n--- LỖI ---\")\n",
    "            print(f\"Không thể xử lý video tại index: {i}\")\n",
    "            print(f\"Lỗi chi tiết: {e}\")\n",
    "            print(f\"-------------\\n\")\n",
    "\n",
    "    print(\"\\n=====================================\")\n",
    "    print(\"HOÀN TẤT XỬ LÝ TOÀN BỘ DỮ LIỆU!\")\n",
    "    print(f\"Dữ liệu keypoint đã được lưu tại: {output_dir}\")\n",
    "    print(\"=====================================\")\n",
    "\n",
    "# --- 4. CHẠY SCRIPT ---\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.simplefilter(\"always\")\n",
    "\n",
    "    # Thư mục bạn muốn lưu file .npy vào\n",
    "    KEYPOINT_DATA_ROOT = \"Keypoint_Dataset_HF\"\n",
    "\n",
    "    # Tải dataset\n",
    "    print(\"Đang tải dataset (sẽ dùng cache nếu có)...\")\n",
    "    raw_ds = load_dataset(\"asthalochan/American_Sign_Language\")\n",
    "\n",
    "    # Chạy xử lý\n",
    "    process_huggingface_dataset(raw_ds, KEYPOINT_DATA_ROOT)"
   ],
   "id": "acd7133a8d608fe8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải dataset (sẽ dùng cache nếu có)...\n",
      "Đã tìm thấy 47 nhãn.\n",
      "Bắt đầu xử lý 3590 video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang xử lý dataset:   1%|▏         | 47/3590 [02:30<3:09:05,  3.20s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
