{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-11T16:25:19.086692Z",
     "start_time": "2025-11-11T16:25:11.684937Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "import json\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# --- PHẦN 1: ĐỊNH NGHĨA LẠI KIẾN TRÚC MÔ HÌNH ---\n",
    "# (Không thay đổi - Giống hệt code trước)\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class KeypointTransformerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, d_model, nhead, num_encoder_layers,\n",
    "                 dim_feedforward, dropout, input_features=1662, max_seq_len=128):\n",
    "        super(KeypointTransformerClassifier, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.input_embedding = nn.Linear(input_features, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len=max_seq_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, num_layers=num_encoder_layers\n",
    "        )\n",
    "        self.classifier_head = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.input_embedding(src) * math.sqrt(self.d_model)\n",
    "        src = src.permute(1, 0, 2)\n",
    "        src = self.pos_encoder(src)\n",
    "        src = src.permute(1, 0, 2)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.mean(dim=1)\n",
    "        output = self.classifier_head(output)\n",
    "        return output\n",
    "\n",
    "# --- PHẦN 2: CÁC HÀM HỖ TRỢ XỬ LÝ VIDEO & KEYPOINT ---\n",
    "# (Không thay đổi - Giống hệt code trước)\n",
    "mp_holistic = mp.solutions.holistic\n",
    "NUM_POSE_LANDMARKS = 33\n",
    "NUM_FACE_LANDMARKS = 468\n",
    "NUM_HAND_LANDMARKS = 21\n",
    "ZERO_POSE = np.zeros(NUM_POSE_LANDMARKS * 4)\n",
    "ZERO_FACE = np.zeros(NUM_FACE_LANDMARKS * 3)\n",
    "ZERO_HAND = np.zeros(NUM_HAND_LANDMARKS * 3)\n",
    "\n",
    "def extract_holistic_keypoints(video_frames_rgb_list):\n",
    "    all_frame_keypoints = []\n",
    "    with mp_holistic.Holistic(\n",
    "        static_image_mode=False,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        for frame in video_frames_rgb_list:\n",
    "            results = holistic.process(frame)\n",
    "            pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else ZERO_POSE\n",
    "            face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else ZERO_FACE\n",
    "            lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else ZERO_HAND\n",
    "            rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else ZERO_HAND\n",
    "            frame_keypoints = np.concatenate([pose, face, lh, rh])\n",
    "            all_frame_keypoints.append(frame_keypoints)\n",
    "\n",
    "    return np.array(all_frame_keypoints).astype(np.float32)\n",
    "\n",
    "def read_video_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Lỗi: Không thể mở file video: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    all_frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        all_frames.append(frame_rgb)\n",
    "    cap.release()\n",
    "    return all_frames\n",
    "\n",
    "# --- PHẦN 3: HÀM SUY LUẬN (INFERENCE) CHÍNH ---\n",
    "# *** ĐÃ SỬA ĐỔI LOGIC TRONG HÀM NÀY ***\n",
    "\n",
    "def predict_video(model, video_path, label_map_inverse, device, max_seq_len, num_features):\n",
    "    \"\"\"\n",
    "    Pipeline hoàn chỉnh: Đọc video, trích xuất, tiền xử lý (CENTER TRIM), và dự đoán.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # 1. Đọc video -> list các frame\n",
    "    frames = read_video_frames(video_path)\n",
    "    if frames is None or len(frames) == 0:\n",
    "        return \"Lỗi: Không thể đọc video\", 0.0\n",
    "\n",
    "    # 2. Trích xuất Keypoints (List[frame] -> mảng NumPy (T, 1662))\n",
    "    keypoints = extract_holistic_keypoints(frames)\n",
    "\n",
    "    # 3. Tiền xử lý (Đệm/Cắt)\n",
    "    num_frames = keypoints.shape[0]\n",
    "\n",
    "    # =========================================================\n",
    "    # --- BẮT ĐẦU THAY ĐỔI LOGIC (Center Trim) ---\n",
    "    if num_frames == max_seq_len:\n",
    "        # Vừa đủ, không làm gì\n",
    "        pass\n",
    "    elif num_frames > max_seq_len:\n",
    "        # TRƯỚC ĐÂY (Cắt đầu):\n",
    "        # keypoints = keypoints[:max_seq_len, :]\n",
    "\n",
    "        # HIỆN TẠI (Cắt giữa):\n",
    "        # 1. Tính toán điểm bắt đầu để lấy clip ở giữa\n",
    "        start_idx = (num_frames - max_seq_len) // 2\n",
    "\n",
    "        # 2. Lấy lát cắt từ giữa\n",
    "        keypoints = keypoints[start_idx : start_idx + max_seq_len, :]\n",
    "\n",
    "    else: # num_frames < max_seq_len\n",
    "        # Đệm (Pad) nếu ngắn hơn (Logic này không đổi)\n",
    "        padding_needed = max_seq_len - num_frames\n",
    "        padding_tensor = np.zeros((padding_needed, num_features), dtype=np.float32)\n",
    "        keypoints = np.concatenate([keypoints, padding_tensor], axis=0)\n",
    "    # --- KẾT THÚC THAY ĐỔI LOGIC ---\n",
    "    # =========================================================\n",
    "\n",
    "    # 4. Chuyển sang Tensor và thêm chiều Batch (B=1)\n",
    "    input_tensor = torch.from_numpy(keypoints)\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # 5. Suy luận\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "\n",
    "        # 6. Hậu xử lý: Lấy xác suất\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        confidence, predicted_id = torch.max(probabilities, 1)\n",
    "\n",
    "        predicted_id = predicted_id.item()\n",
    "        confidence = confidence.item()\n",
    "\n",
    "        # 7. Map ID sang Tên nhãn (ví dụ: 5 -> 'hello')\n",
    "        prediction_name = label_map_inverse.get(predicted_id, \"KHÔNG RÕ NHÃN\")\n",
    "\n",
    "        return prediction_name, confidence\n",
    "\n",
    "# --- PHẦN 4: THỰC THI SCRIPT ---\n",
    "# (Không thay đổi - Giống hệt code trước)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "    # --- CÁC THAM SỐ (PHẢI GIỐNG HỆT FILE HUẤN LUYỆN) ---\n",
    "\n",
    "    # *** (QUAN TRỌNG) HÃY SỬA 3 ĐƯỜNG DẪN NÀY ***\n",
    "    LABEL_MAP_PATH = \"label_map.json\"\n",
    "    MODEL_PATH = \"best_transformer_model.pth\"\n",
    "    VIDEO_TO_TEST = \"Video_Internet/father.mp4\"\n",
    "\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    # Tham số mô hình (PHẢI GIỐNG HỆT FILE HUẤN LUYỆN)\n",
    "    NUM_FEATURES = 1662\n",
    "    MAX_SEQ_LEN = 128\n",
    "    D_MODEL = 512\n",
    "    NHEAD = 8\n",
    "    NUM_ENCODER_LAYERS = 4\n",
    "    DIM_FEEDFORWARD = 2048\n",
    "    DROPOUT = 0.1\n",
    "\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Sử dụng thiết bị: {DEVICE}\")\n",
    "\n",
    "    # --- Bước 1: Tải và Tái tạo Label Map ---\n",
    "    label_map = None\n",
    "    label_map_inverse = None\n",
    "    NUM_CLASSES = 0\n",
    "\n",
    "    print(f\"Đang tải bản đồ nhãn từ: '{LABEL_MAP_PATH}'...\")\n",
    "    try:\n",
    "        with open(LABEL_MAP_PATH, 'r', encoding='utf-8') as f:\n",
    "            label_map = json.load(f)\n",
    "\n",
    "        NUM_CLASSES = len(label_map)\n",
    "        label_map_inverse = {idx: label for label, idx in label_map.items()}\n",
    "        print(f\"Tải và tái tạo {NUM_CLASSES} nhãn thành công.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"LỖI: Không tìm thấy file bản đồ nhãn: '{LABEL_MAP_PATH}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file JSON: {e}\")\n",
    "\n",
    "    # Chỉ tiếp tục nếu tải bản đồ nhãn thành công\n",
    "    if label_map and label_map_inverse:\n",
    "\n",
    "        # --- Bước 2: Tải Mô hình ---\n",
    "        print(f\"Đang tải mô hình từ '{MODEL_PATH}'...\")\n",
    "        try:\n",
    "            model = KeypointTransformerClassifier(\n",
    "                num_classes=NUM_CLASSES, d_model=D_MODEL, nhead=NHEAD,\n",
    "                num_encoder_layers=NUM_ENCODER_LAYERS, dim_feedforward=DIM_FEEDFORWARD,\n",
    "                dropout=DROPOUT, input_features=NUM_FEATURES, max_seq_len=MAX_SEQ_LEN\n",
    "            )\n",
    "            model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "            model.to(DEVICE)\n",
    "            model.eval()\n",
    "            print(\"Tải mô hình thành công.\")\n",
    "\n",
    "            # --- Bước 3: Chạy Suy luận ---\n",
    "            print(f\"\\n--- Bắt đầu dự đoán video: {VIDEO_TO_TEST} ---\")\n",
    "            if not os.path.exists(VIDEO_TO_TEST):\n",
    "                print(f\"LỖI: Không tìm thấy file video: {VIDEO_TO_TEST}\")\n",
    "            else:\n",
    "                prediction, confidence = predict_video(\n",
    "                    model=model,\n",
    "                    video_path=VIDEO_TO_TEST,\n",
    "                    label_map_inverse=label_map_inverse,\n",
    "                    device=DEVICE,\n",
    "                    max_seq_len=MAX_SEQ_LEN,\n",
    "                    num_features=NUM_FEATURES\n",
    "                )\n",
    "\n",
    "                print(\"\\n================ KẾT QUẢ DỰ ĐOÁN ================\")\n",
    "                print(f\"== Video: {VIDEO_TO_TEST}\")\n",
    "                print(f\"== Dự đoán: {prediction.upper()}\")\n",
    "                print(f\"== Độ tự tin: {confidence * 100:.2f}%\")\n",
    "                print(\"==================================================\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"LỖI: Không tìm thấy file trọng số '{MODEL_PATH}'\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"LỖI khi tải mô hình: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Đã xảy ra lỗi không xác định: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng thiết bị: cpu\n",
      "Đang tải bản đồ nhãn từ: 'label_map.json'...\n",
      "Tải và tái tạo 47 nhãn thành công.\n",
      "Đang tải mô hình từ 'best_transformer_model.pth'...\n",
      "Tải mô hình thành công.\n",
      "\n",
      "--- Bắt đầu dự đoán video: Video_Internet/father.mp4 ---\n",
      "\n",
      "================ KẾT QUẢ DỰ ĐOÁN ================\n",
      "== Video: Video_Internet/father.mp4\n",
      "== Dự đoán: NO\n",
      "== Độ tự tin: 97.87%\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
